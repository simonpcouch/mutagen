---
title: "Pharmaceutical machine learning with tidymodels and Posit Connect"
format: html
editor: visual
description: "A group of scientists investigate whether they can use drug information to predict if a proposed drug could be a mutagen (i.e. toxicity caused by damage to DNA). Deploying a tidymodels machine learning model with Posit Connect, these scientists can rapidly assess new drugs for their potential harm to patients."
---

```{r load}
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(tidymodels)
library(bundle)
library(vetiver)
library(pins)

load("data/mutagen_tbl.Rda")
load("data/metrics_wf_set.Rda")
load("data/metrics_xgb.Rda")
load("data/xgb_final_fit.Rda")
load("data/final_fit.Rda")
```

In pharmaceutical research, mutagenicity refers to a drug's tendency to increase the rate of mutations due to the damage of genetic material, a key indicator that a drug may be a carcinogen. Mutagenicity can be evaluated using a lab test, though the test requires experienced scientists and time in the lab. A group of scientists are studying whether, instead, they can use known information to quickly [predict the mutagenicity of new drugs](doi.org/10.1021/jm040835a).

The open-source [tidymodels packages for machine learning](https://www.tidymodels.org/) empower these scientists to quickly propose, train, and evaluate a diversity of statistical approaches to predict mutagenicity. Based on their findings, the most performant machine learning model can then be integrated into a [plumber API](https://www.rplumber.io/) using [Posit Connect](https://posit.co/products/enterprise/connect/), allowing scientists across the organization to quickly input drug information and evaluate the potential for drugs to harm patients.

This post will outline the steps to develop and deploy a machine learning model to predict drug mutagenicity. All of the source code for this process is available at [https://github.com/simonpcouch/mutagen](https://github.com/simonpcouch/mutagen).

## Training Data

The [training data](https://CRAN.R-project.org/package=QSARdata) consists of `r nrow(mutagen_tbl)` rows and `r ncol(mutagen_tbl)` columns, where the first column gives the outcome of the lab test for a given proposed drug, and the remaining columns give known information about the chemical structure of the drug. This information about the chemical structure can be obtained much more quickly and cheaply than the outcome---in the future, scientists want to be able to predict whether a drug is a mutagen based only on the drug information.

```{r print-mutagen}
#| echo: false
mutagen_tbl
```

No particular predictor will allow us to straightforwardly predict whether a drug may be a mutagen. We can plot two commonly used predictors against the outcome to demonstrate:

```{r plot-mutagen}
#| fig-alt: "A ggplot2 dot-plot, with predictors MW and MLOGP on the x and y axes. Points are colored depending on the outcome, with red denoting mutagens and green denoting nonmutagens. The red and green clouds of points are largely intermixed, showing that these two predictors do not separate these classes well on their own."
#| echo: false
ggplot(mutagen_tbl) +
  aes(x = MW, y = MLOGP, color = outcome) +
  geom_point() +
  labs(x = "Mol. Weight", y = "Partition Coefficient") +
  theme_minimal() +
  scale_color_manual(values = c("#ba0600", "#71b075"))
```

However, using machine learning, we may be able find patterns hidden among all of this data to predict whether a drug is a mutagen or not.

## Developing The Model

The [tidymodels packages](https://www.tidymodels.org/) provide a consistent interface to hundreds of machine learning models available across the R ecosystem. This consistency allows us to quickly try out a diversity of statistical approaches, relying on tidymodels to protect us from common modeling pitfalls and provide rigorous estimates of model performance.

First, we try out a number of different machine learning techniques to model the mutagenicity of these drugs and judge their effectiveness using a metric called the [area under the ROC curve](https://bookdown.org/max/FES/measuring-performance.html#class-metrics "ROC curves"):

```{r plot-wf-set}
#| fig-alt: "A ggplot2 faceted boxplot, where different model types are on the x-axis and the out-of-sample ROC AUCs associated with those models are on the y-axis. The shown metrics values range from 0 to around 0.9. The x-axis is roughly sorted by descending ROC AUC, where the left-most model, XGBoost Boosted Tree, tends to have the best performance. Other models proposed were, from left to right, Bagged Decision Tree, Support Vector Machine, Logistic Regression, Bagged MARS, and Neural Network."
#| echo: false
metrics_wf_set %>%
  mutate(
    model = case_when(
      model == "boost_tree" ~ "XGBoost Boosted Tree",
      model == "logistic_reg" ~ "Logistic Regression",
      model == "bag_tree" ~ "Bagged Decision Tree",
      model == "bag_mars" ~ "Bagged MARS",
      model == "svm_rbf" ~ "Support Vector Machine",
      model == "mlp" ~ "Neural Networks"
    )
  ) %>%
  filter(.metric == "roc_auc") %>%
  arrange(desc(.estimate)) %>%
  mutate(model = fct_inorder(model)) %>%
  select(Model = model, `ROC AUC` = .estimate) %>%
  ggplot() +
  aes(x = Model, y = `ROC AUC`) +
  geom_boxplot() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```

Based on the above plot, we see that a boosted tree model fitted with XGBoost consistently outperforms other models we evaluate, with out-of-sample ROC scores above 0.85 (a value of 1.0 is best). We will thus use these initial results to optimize our XGBoost model further with an approach called [*simulated annealing*](https://finetune.tidymodels.org/reference/tune_sim_anneal.html):

```{r plot-sim-anneal}
#| fig-alt: "A ggplot2 faceted boxplot, where the x-axis gives iterations ranging from 0 to 25, and the y-axis gives the distribution of out-of-sample ROC AUCs for that iteration. With some exceptions in iterations 14 through 17, the interquartile range in most iterations is 0.86 to 0.92."
#| echo: false
metrics_xgb %>%
  filter(.metric == "roc_auc") %>%
  mutate(`ROC AUC` = .estimate, Iteration = as.factor(.iter)) %>%
  ggplot() +
  aes(x = Iteration, y = `ROC AUC`) +
  geom_boxplot() +
  theme_minimal()
```

```{r sim-anneal-metrics}
#| include: false
metrics_sum <- metrics_xgb %>%
  filter(.metric == "roc_auc") %>%
  group_by(.iter) %>%
  summarize(mean = mean(.estimate))

max_mean_pos <- which.max(metrics_sum$mean)
best_iter <- metrics_sum$.iter[max_mean_pos]
best_roc <- metrics_sum$mean[max_mean_pos]

test_roc <- 
  collect_metrics(xgb_final_fit) %>%
  filter(.metric == "roc_auc") %>%
  pull(.estimate)
```

Simulated annealing performs an *iterative search*, using results from previous iterations to inform later optimizations. In this search, we see that optimizations made in early iterations resulted in higher ROC scores. The search evaluated then proposed optimizations that resulted in less performant models before discovering more performant optimizations later on, giving a maximum out-of-sample ROC score of `r round(best_roc, 3)`. Fitting the best model to the full training set, we see a final test set ROC score of `r round(test_roc, 3)`, indicating that our model generalizes well to data it hasn't yet seen.

## Model Deployment

With our final model fitted and benchmarked, it's time to put this model into practice. Using [vetiver](https://vetiver.rstudio.com/), a multilingual MLOps framework, we can quickly develop a [plumber API](https://www.rplumber.io/) to provide a user-friendly interface to the fitted model. We then host the app on [Posit Connect](https://posit.co/products/enterprise/connect/), providing a safe and performant server to provide model predictions to practitioners within our organization.

```{r deploy}
#| eval: false
#| include: false
final_fit_unbundled <- unbundle(final_fit)

final_fit_vetiver <- vetiver_model(final_fit_unbundled, "mutagen")

board <- board_connect()

vetiver_pin_write(board, final_fit_vetiver)

vetiver_deploy_rsconnect(board, "simon.couch/mutagen")
```

![](figures/connect_mutagen.gif){fig-alt="A GIF screenshot of a Posit Connect instance hosting the vetiver model's plumber API, titled Mutagen Model API. The cursor first navigates over four user-facing tabs, providing templates for pinging, pinning, and predicting using the hosted model. A sidebar for Posit Connect gives additional controls for metadata, security, and scheduling."}

The vetiver plumber API provides documentation and templates for generating predictions from the deployed model. Hosting the API on Posit Connect allows us to easily edit the model's metadata and documentation, securely manage permissions among our organization, and monitor the model's usage.

----

All of the source code for data pre-processing, model training, and deployment to Posit Connect with vetiver is publicly available at [https://github.com/simonpcouch/mutagen](https://github.com/simonpcouch/mutagen).
